{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huxwell/ColabNNs/blob/main/cats_n_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.__version__\n",
        "# !pip uninstall torch -y\n",
        "# !pip install torch==1.11.0"
      ],
      "metadata": {
        "id": "qifzSNc8bcee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGsOW96X9y6u"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0XYxT3MBckL"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import random # do random.seed(13) before every shuffle. order of shuffle() execution changes results order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMdiSs9-eB7j"
      },
      "source": [
        "Notes:\n",
        "- I have no labels for test here, so I am dropping 'test.zip' related code. I can split train into train, val, test; in fact I don't want to have a lot of examples for train set.\n",
        "- The sets are almost balanced, accuracy is ok here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZRBEouz9xuT"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(13)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw2dMvob99Dd"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/drive/MyDrive/cats_n_dogs_unsure/dogs-vs-cats-redux-kernels-edition'\n",
        "subset_bad_crops_path = '/content/drive/MyDrive/cats_n_dogs_unsure/cat_dogs_crops_from_test_20k_filtered.zip'\n",
        "subset_multi_path = '/content/drive/MyDrive/cat_dogs_8_contats_50_50_from_test.zip'\n",
        "os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8slOqO8-IUw"
      },
      "outputs": [],
      "source": [
        "os.makedirs('local_data/', exist_ok=True)\n",
        "train_dir = 'local_data/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JytonT65-L6A"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(os.path.join(dataset_dir, 'train.zip')) as train_zip:\n",
        "    train_zip.extractall('local_data')\n",
        "\n",
        "with zipfile.ZipFile(subset_bad_crops_path) as bad_crops_zip:\n",
        "    bad_crops_zip.extractall('local_data')\n",
        "\n",
        "with zipfile.ZipFile(subset_multi_path) as multi_zip:\n",
        "    multi_zip.extractall('local_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzvXLys8CNY5"
      },
      "outputs": [],
      "source": [
        "os.listdir(train_dir)[:5]\n",
        "os.listdir('/content/local_data/cat_dogs_8_contats_50_50_from_test')[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCmaWu9nfx9V"
      },
      "outputs": [],
      "source": [
        "cats_list = sorted(glob.glob(os.path.join(train_dir,'cat*.jpg')))\n",
        "dogs_list = sorted(glob.glob(os.path.join(train_dir,'dog*.jpg')))\n",
        "bad_cats_generated_from_test_list = sorted(glob.glob(os.path.join(\"local_data/cat_dogs_crops_from_test_20k_filtered/filtered_cats\",'cat*.jpg')))\n",
        "bad_dogs_generated_from_test_list = sorted(glob.glob(os.path.join(\"local_data/cat_dogs_crops_from_test_20k_filtered/filtered_dogs\",'dog*.jpg')))\n",
        "concat_8_50_50_list = sorted(glob.glob(os.path.join(\"local_data/cat_dogs_8_contats_50_50_from_test/\",'cat_dog_50_50_8concats_*_224x224resize.jpg')))\n",
        "\n",
        "print(concat_8_50_50_list[:5])\n",
        "print(len(concat_8_50_50_list))\n",
        "\n",
        "print(len(bad_cats_generated_from_test_list))\n",
        "print(len(bad_dogs_generated_from_test_list))\n",
        "print(len(cats_list))\n",
        "print(len(dogs_list))\n",
        "random.seed(13)\n",
        "random.shuffle(cats_list)\n",
        "random.seed(13) #multiple seed() executions are on purpose.\n",
        "random.shuffle(dogs_list)\n",
        "print(cats_list[:3])\n",
        "print(dogs_list[:3])\n",
        "# some sanity check to make sure no uncontrolled randomness beyond this point\n",
        "assert cats_list[2] == 'local_data/train/cat.801.jpg'\n",
        "assert dogs_list[2] == 'local_data/train/dog.801.jpg'\n",
        "assert len(cats_list) == len(dogs_list)\n",
        "\n",
        "\n",
        "random.seed(13)\n",
        "random.shuffle(bad_cats_generated_from_test_list)\n",
        "random.seed(13)\n",
        "random.shuffle(bad_dogs_generated_from_test_list)\n",
        "print(bad_cats_generated_from_test_list[:3])\n",
        "print(bad_dogs_generated_from_test_list[:3])\n",
        "assert bad_cats_generated_from_test_list[1] == 'local_data/cat_dogs_crops_from_test_20k_filtered/filtered_cats/cat.5232_crop_e_2.jpg'\n",
        "assert bad_dogs_generated_from_test_list[1] == 'local_data/cat_dogs_crops_from_test_20k_filtered/filtered_dogs/dog.3799_crop_e_2.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADT-iYGCiOMg"
      },
      "outputs": [],
      "source": [
        "full_train_list = cats_list[:7500] + dogs_list[:7500]\n",
        "# subset_train_list = cats_list[:500] + dogs_list[:500]\n",
        "# subset_train_list = cats_list[:1000] + dogs_list[:1000]\n",
        "# subset_train_list = cats_list[:2000] + dogs_list[:2000]\n",
        "# subset_train_list = cats_list[:250] + dogs_list[:250]\n",
        "# subset_train_list = cats_list[:150] + dogs_list[:150]\n",
        "# subset_train_list = cats_list[:250] + dogs_list[:250] + bad_cats_generated_from_test_list[:100] + bad_dogs_generated_from_test_list[:100]\n",
        "# subset_train_list = cats_list[:500] + dogs_list[:500] + bad_cats_generated_from_test_list[:200] + bad_dogs_generated_from_test_list[:200]\n",
        "\n",
        "# subset_train_list = cats_list[:50] + dogs_list[:50] + bad_cats_generated_from_test_list[:20] + bad_dogs_generated_from_test_list[:20]\n",
        "\n",
        "# subset_train_list = cats_list[:2000] + dogs_list[:2000] + bad_cats_generated_from_test_list[:800] + bad_dogs_generated_from_test_list[:800]\n",
        "# subset_train_list = cats_list[:1000] + dogs_list[:1000] + bad_cats_generated_from_test_list[:400] + bad_dogs_generated_from_test_list[:400]\n",
        "# subset_train_list = cats_list[:1000] + dogs_list[:1000] + concat_8_50_50_list[:400]\n",
        "\n",
        "# subset_train_list = cats_list[:1000] + dogs_list[:1000] + concat_8_50_50_list[:400]\n",
        "# subset_train_list = cats_list[:2000] + dogs_list[:2000] + concat_8_50_50_list[:800]\n",
        "\n",
        "# subset_train_list = cats_list[:500] + dogs_list[:500] + concat_8_50_50_list[:400]\n",
        "# subset_train_list = cats_list[:500] + dogs_list[:500] + concat_8_50_50_list[:200]\n",
        "# subset_train_list = cats_list[:2000] + dogs_list[:2000] + concat_8_50_50_list[:1600]\n",
        "\n",
        "# subset_train_list = cats_list[:50] + dogs_list[:50] + concat_8_50_50_list[:40]\n",
        "\n",
        "# subset_train_list = cats_list[:250] + dogs_list[:250] + concat_8_50_50_list[:200]\n",
        "subset_train_list = cats_list[:250] + dogs_list[:250] + concat_8_50_50_list[:100]\n",
        "\n",
        "\n",
        "val_list = cats_list[7500:10000] + dogs_list[7500:10000]\n",
        "test_list = cats_list[10000:] + dogs_list[10000:]\n",
        "print(len(subset_train_list),len(full_train_list), len(val_list), len(test_list))\n",
        "\n",
        "random.seed(13)\n",
        "random.shuffle(full_train_list)\n",
        "random.seed(13)\n",
        "random.shuffle(subset_train_list)\n",
        "random.seed(13)\n",
        "random.shuffle(val_list)\n",
        "random.seed(13)\n",
        "random.shuffle(test_list)\n",
        "print(\"full\",full_train_list[:9])\n",
        "print(\"subset\",subset_train_list[:9])\n",
        "print(\"val\",val_list[:9])\n",
        "print(\"test\",test_list[:9])\n",
        "assert full_train_list[4] == 'local_data/train/cat.1612.jpg'\n",
        "# assert subset_train_list[4] == 'local_data/cat_dogs_crops_from_test_20k_filtered/filtered_cats/cat.2922_crop_e_0.jpg' #500 + 200 bad crop imgs train\n",
        "# assert subset_train_list[1] == 'local_data/cat_dogs_crops_from_test_20k_filtered/filtered_cats/cat.4044_crop_e_3.jpg' #1000 + 400 bad crop imgs train\n",
        "# assert subset_train_list[3] == 'local_data/cat_dogs_crops_from_test_20k_filtered/filtered_dogs/dog.4554_crop_e_2.jpg' #100 + 40 bad crop imgs train\n",
        "# assert subset_train_list[0] == 'local_data/cat_dogs_crops_from_test_20k_filtered/filtered_dogs/dog.501_crop_e_0.jpg' #2000 + 800 bad crop imgs train\n",
        "# assert subset_train_list[3] == 'local_data/cat_dogs_8_contats_50_50_from_test/cat_dog_50_50_8concats_1123_224x224resize.jpg' #2000 + 400 0.5 0.5\n",
        "\n",
        "\n",
        "# assert subset_train_list[1] == 'local_data/cat_dogs_8_contats_50_50_from_test/cat_dog_50_50_8concats_1103_224x224resize.jpg' #1000 + 400 0.5 0.5\n",
        "# assert subset_train_list[1] == 'local_data/cat_dogs_8_contats_50_50_from_test/cat_dog_50_50_8concats_1859_224x224resize.jpg' #4000 + 1600 0.5 0.5\n",
        "\n",
        "# assert subset_train_list[3] == 'local_data/cat_dogs_8_contats_50_50_from_test/cat_dog_50_50_8concats_1032_224x224resize.jpg' #100 + 40 0.5 0.5\n",
        "# assert subset_train_list[2] == 'local_data/cat_dogs_8_contats_50_50_from_test/cat_dog_50_50_8concats_1123_224x224resize.jpg' #500 + 200 0.5 0.5\n",
        "\n",
        "assert subset_train_list[4] == 'local_data/cat_dogs_8_contats_50_50_from_test/cat_dog_50_50_8concats_1067_224x224resize.jpg' #500 + 100 0.5 0.5\n",
        "\n",
        "\n",
        "# assert subset_train_list[3] == 'local_data/cat_dogs_8_contats_50_50_from_test/cat_dog_50_50_8concats_1007_224x224resize.jpg' #1000 + 200 0.5 0.5\n",
        "\n",
        "\n",
        "# assert subset_train_list[1] == 'local_data/cat_dogs_crops_from_test_20k_filtered/filtered_dogs/dog.4650_crop_e_0.jpg' #4000 + 1600 bad crop imgs train\n",
        "\n",
        "# assert subset_train_list[4] == 'local_data/train/cat.1787.jpg' #500imgs train\n",
        "# assert subset_train_list[4] == 'local_data/train/cat.5360.jpg' #4000 imgs train\n",
        "# assert subset_train_list[4] == 'local_data/train/dog.445.jpg' # 1000 imgs train\n",
        "# assert subset_train_list[4] == 'local_data/train/dog.7661.jpg' # 300 imgs\n",
        "# assert subset_train_list[4] == 'local_data/train/cat.9914.jpg' #100 imgs\n",
        "# assert subset_train_list[4] == 'local_data/train/dog.11151.jpg'#2000imgs train\n",
        "assert val_list[4] == 'local_data/train/dog.12023.jpg'\n",
        "assert test_list[4] == 'local_data/train/dog.6485.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_iriJP1lzl4"
      },
      "outputs": [],
      "source": [
        "train_list = subset_train_list # 5 batches # or 20 batches\n",
        "# train_list = full_train_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgRVni0iCVkg"
      },
      "outputs": [],
      "source": [
        "np.random.seed(13131313)\n",
        "random_idx = np.random.randint(1,len(train_list),size=10)\n",
        "print(random_idx)\n",
        "fig = plt.figure(figsize=(20., 10.))\n",
        "\n",
        "for i, img_idx in enumerate(random_idx):\n",
        "    ax = fig.add_subplot(2,5,i+1)\n",
        "    img = Image.open(train_list[img_idx])\n",
        "    plt.imshow(img)\n",
        "    i+=1\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpFt-8n8DgfT"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM5LfbFcDf_Y"
      },
      "outputs": [],
      "source": [
        "train_transforms =  transforms.Compose([ #these params work well for cats & dogs.:\n",
        "  # transforms.Resize((224, 224)),\n",
        "  transforms.RandomResizedCrop(224,scale=(0.9, 1.0)), \n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ColorJitter(brightness=.4, hue=.15),\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "  transforms.Resize((224, 224)),\n",
        "  # transforms.RandomResizedCrop(224),\n",
        "  # transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([   \n",
        "  transforms.Resize((224, 224)),\n",
        "  # transforms.RandomResizedCrop(224),\n",
        "  # transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hard_label(img_path):\n",
        "  label = img_path.split('/')[-1].split('.')[0]\n",
        "  if label == 'dog':\n",
        "    return 1\n",
        "  elif label == 'cat':\n",
        "    return 0\n",
        "\n",
        "def get_soft_label_inbalanced(img_path):\n",
        "  label = img_path.split('/')[-1].split('.')[0]\n",
        "  if label == 'dog':\n",
        "      if \"crop\" in img_path:\n",
        "        return torch.FloatTensor([0.7,0.3])\n",
        "      else:\n",
        "        return torch.FloatTensor([1.0,0.0])\n",
        "  elif label == 'cat':\n",
        "      if \"crop\" in img_path:\n",
        "        return torch.FloatTensor([0.3,0.7])\n",
        "      else:\n",
        "        return torch.FloatTensor([0.0,1.0])\n",
        "\n",
        "def get_soft_label_balanced(img_path):\n",
        "  label = img_path.split('/')[-1].split('.')[0]\n",
        "  if \"cat\" in label and \"dog\" in label and \"concat\" in label:\n",
        "      return torch.FloatTensor([0.5,0.5])\n",
        "  elif label == 'dog':\n",
        "      return torch.FloatTensor([1.0,0.0])\n",
        "  elif label == 'cat':\n",
        "      return torch.FloatTensor([0.0,1.0])"
      ],
      "metadata": {
        "id": "D0j3SM6Azt6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-TsOoMoDsur"
      },
      "outputs": [],
      "source": [
        "class dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,file_list,transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        \n",
        "    #dataset length\n",
        "    def __len__(self):\n",
        "        self.filelength = len(self.file_list)\n",
        "        return self.filelength\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        img = Image.open(img_path)\n",
        "        img_transformed = self.transform(img)\n",
        "        \n",
        "        # print(\"===========\")\n",
        "        # print(\"img path\", img_path)\n",
        "        label = get_soft_label_balanced(img_path)\n",
        "\n",
        "        # print(\"label\", label)\n",
        "            \n",
        "        return img_transformed,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrrBRLdwbIDR"
      },
      "outputs": [],
      "source": [
        "## Visualization of Image Classification \n",
        "import torchvision\n",
        "def visualize_classification(loader_iter, nrofItems = 9, pad = 0) -> None:\n",
        "\n",
        "  #Iterate through the data loader\n",
        "  imgTensor, labels = next(loader_iter)\n",
        "  labels = labels.tolist()\n",
        "\n",
        "  # Generate image grid\n",
        "  grid = torchvision.utils.make_grid(imgTensor[:nrofItems], padding = pad, nrow=nrofItems)\n",
        "\n",
        "  # Permute the axis as numpy expects image of shape (H x W x C) \n",
        "  grid = grid.permute(1, 2, 0)\n",
        "  \n",
        "  # Set up plot config\n",
        "  plt.figure(figsize=(8, 2), dpi=300)\n",
        "  plt.axis('off')\n",
        "\n",
        "  # Plot Image Grid\n",
        "  plt.imshow(grid)\n",
        "  \n",
        "  # # Plot the image titles\n",
        "  # fact = 1 + (nrofItems)/100\n",
        "  # rng = np.linspace(1/(fact*nrofItems), 1 - 1/(fact*nrofItems) , num = nrofItems)\n",
        "  # for idx, val in enumerate(rng):\n",
        "  #   plt.figtext(val, 0.85, labels[idx], fontsize=8)\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8koteIep9wIW"
      },
      "outputs": [],
      "source": [
        "batch_size = 100 # we will use mini-batch method\n",
        "# batch_size = 4 # 10 TODO change this after going back to GPU! this is because notebook crashes when whole RAM is used # using 1 because of soft softmax bug/opti in pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ2krjGVDzuk"
      },
      "outputs": [],
      "source": [
        "train_data = dataset(train_list, transform=train_transforms)\n",
        "val_data = dataset(val_list, transform=val_transforms)\n",
        "test_data = dataset(test_list, transform=test_transforms)\n",
        "visualise_train_dataset = dataset(train_list, transform=train_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=False )\n",
        "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=batch_size, shuffle=False)\n",
        "vis_train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=10, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HUV6nHWAn115"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Iy8VyU1gqkD"
      },
      "outputs": [],
      "source": [
        "# this cell is here only because the Author apprently didn't understand how Dataset and Dataloaders behave - are they iterable, are they generators? - well they are hybrid. - , and wanted to see what happens\n",
        "# all but one cell can be commented\n",
        "# TODO: you don't need a separate loader. each iteration goes from the beginning\n",
        "# but its interesting that different augmentations get generated.\n",
        "iterator = iter(vis_train_loader)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iter(vis_train_loader))\n",
        "visualize_classification(iter(vis_train_loader))\n",
        "visualize_classification(iter(vis_train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWizETdhD1h0"
      },
      "outputs": [],
      "source": [
        "print(len(train_data), len(train_loader), len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAfRCxgVbseH"
      },
      "outputs": [],
      "source": [
        "print(sum(1 for filename in train_data.file_list if 'cat' in filename))\n",
        "print(sum(1 for filename in train_data.file_list if 'dog' in filename))\n",
        "print(sum(1 for filename in val_data.file_list if 'cat' in filename))\n",
        "print(sum(1 for filename in val_data.file_list if 'dog' in filename))\n",
        "print(sum(1 for filename in test_data.file_list if 'cat' in filename))\n",
        "print(sum(1 for filename in test_data.file_list if 'dog' in filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v2wAJjCD3Ip"
      },
      "outputs": [],
      "source": [
        "#check our images shape\n",
        "train_data[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# activations = torch.FloatTensor([[-0.3139, -0.0486],\n",
        "# [-0.0510,  0.0470],\n",
        "# [ 0.0963,  0.0143],\n",
        "# [-0.2151, -0.0576]])\n",
        "\n",
        "# targets_float = torch.FloatTensor([1.0, 1.0, 0.0, 0.5])\n",
        "# targets_long = torch.LongTensor([1, 1, 0, 0])\n",
        "# targets_float = torch.FloatTensor([[t, 1-t] for t in targets_float])\n",
        "# print(targets_float)\n",
        "# print(targets_float.shape)\n",
        "# crit = nn.CrossEntropyLoss()\n",
        "# crit(activations,targets_long) # tensor(0.6606)\n",
        "# crit(activations,targets_float) \n",
        "# # return torch._C._nn.cross_entropy_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index, label_smoothing)\n",
        "# # RuntimeError: expected scalar type Long but found Float"
      ],
      "metadata": {
        "id": "UvSKN6n0kjLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z374VYaVWHul"
      },
      "outputs": [],
      "source": [
        "class Experiment:\n",
        "  epochs = 100 #10\n",
        "  min_val_loss = float('inf')\n",
        "  epochs_since_min_loss = 0\n",
        "  patience = 7\n",
        "  final_scores = {}  \n",
        "\n",
        "  def __init__(self):\n",
        "    self.model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)\n",
        "    self.model.classifier[-1] = nn.Linear(in_features=1280, out_features=2, bias=True)\n",
        "    self.model = self.model.to(device).train()\n",
        "    self.optimizer = optim.Adam(params = self.model.parameters(),lr=0.001)\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  def eval_model(self, loader: torch.utils.data.dataloader.DataLoader, model: nn.Module, description: str=\"Evaluation:\") -> tuple: #[torch.Tensor, torch.Tensor] detailed tuple types only in Python >3.9, colab has 3.8.16\n",
        "    epoch_accuracy=0\n",
        "    epoch_loss =0\n",
        "    with torch.no_grad():\n",
        "      with tqdm(loader, unit=\"iteration\") as tqdm_wrapped_loader:\n",
        "        tqdm_wrapped_loader.set_description(description)\n",
        "        for data, label in tqdm_wrapped_loader:\n",
        "            data = data.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            output = model(data)\n",
        "            # print(output, label)\n",
        "            # loss = run.criterion(output,label.float())\n",
        "            loss = run.criterion(output,label)\n",
        "\n",
        "\n",
        "            # acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "            acc = ((output.argmax(dim=1) == label.argmax(dim=1)).float().mean())\n",
        "\n",
        "            epoch_accuracy += acc/ len(loader)\n",
        "            epoch_loss += loss/ len(loader)\n",
        "            tqdm_wrapped_loader.set_postfix(epoch_accuracy=epoch_accuracy, loss=epoch_loss)\n",
        "    return epoch_accuracy, epoch_loss\n",
        "\n",
        "  def train(self):\n",
        "      for epoch in range(self.epochs):\n",
        "          print(\"\\n\",\"=\"*30,\"\\n\")\n",
        "          epoch_loss = 0\n",
        "          epoch_accuracy = 0\n",
        "          \n",
        "          with tqdm(train_loader, unit=\"iteration\") as tepoch:\n",
        "            \n",
        "            for data, label in tepoch:\n",
        "                tepoch.set_description(f\"Training epoch {epoch}\")\n",
        "                data = data.to(device)\n",
        "                label = label.to(device)\n",
        "                \n",
        "                output = run.model(data)\n",
        "                # print(\"output train\", output, output.shape)\n",
        "\n",
        "                # print(\"target train\", label)\n",
        "                loss = run.criterion(output, label)\n",
        "                # loss = run.criterion(output, label.float())\n",
        "                \n",
        "                run.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                run.optimizer.step()\n",
        "                \n",
        "                acc = ((output.argmax(dim=1) == label.argmax(dim=1)).float().mean())\n",
        "\n",
        "                # acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "\n",
        "                epoch_accuracy += acc/len(train_loader)\n",
        "                epoch_loss += loss/len(train_loader)\n",
        "                tepoch.set_postfix(loss=loss.item(), accuracy=100. * epoch_accuracy)\n",
        "            print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch, epoch_accuracy,epoch_loss))\n",
        "\n",
        "          epoch_val_accuracy,epoch_val_loss = self.eval_model(val_loader, run.model, f\"Validation after epoch {epoch}\")\n",
        "          print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch, epoch_val_accuracy,epoch_val_loss))\n",
        "          scalar_val_loss = epoch_val_loss.item()\n",
        "          if scalar_val_loss < self.min_val_loss:\n",
        "            self.min_val_loss = scalar_val_loss \n",
        "            self.epochs_since_min_loss = 0 \n",
        "            self.final_scores['epoch']=epoch\n",
        "            self.final_scores['epoch_train_accuracy']=epoch_accuracy\n",
        "            self.final_scores['epoch_train_loss']=epoch_loss\n",
        "            self.final_scores['epoch_val_loss']=epoch_val_loss\n",
        "            self.final_scores['epoch_val_accuracy']=epoch_val_accuracy\n",
        "\n",
        "\n",
        "            print(\"New best model, min_val_loss:\", self.min_val_loss)\n",
        "\n",
        "            # epoch_test_accuracy,epoch_test_loss = self.eval_model(test_loader, model, f\"Test after epoch {epoch}\")\n",
        "            # print('Epoch : {}, test_accuracy : {}, test_loss : {}'.format(epoch, epoch_test_accuracy,epoch_test_loss))\n",
        "\n",
        "\n",
        "\n",
        "          else:\n",
        "            self.epochs_since_min_loss+=1\n",
        "            print(\"epochs_since_min_loss\",self.epochs_since_min_loss)\n",
        "          if self.epochs_since_min_loss > self.patience:\n",
        "            print(f\"Early stopping. \\n\\n Best model scores: {self.final_scores}\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = torch.FloatTensor([[-0.1185,  0.7045],\n",
        "        [ 0.3875, -0.1597],\n",
        "        [-0.0238,  0.2865],\n",
        "        [-0.0509,  0.2330]]) \n",
        "\n",
        "label = torch.FloatTensor([[1., 0.],\n",
        "        [1., 0.],\n",
        "        [0.3, 0.7],\n",
        "        [1., 0.]])\n",
        "\n",
        "print(output.argmax(dim=1))\n",
        "print(label.argmax(dim=1))\n",
        "print((output.argmax(dim=1) == label.argmax(dim=1)).float().mean())\n",
        "# acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "# epoch_accuracy += acc/len(train_loader)"
      ],
      "metadata": {
        "id": "Omxcm7AMvGVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81GkYD0_D6ZM"
      },
      "outputs": [],
      "source": [
        "run = Experiment()\n",
        "run.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_FB6xAMBki3"
      },
      "outputs": [],
      "source": [
        "print(f\"Early stopping. \\n\\n Best model scores: {run.final_scores}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGb3zoqwEmWl"
      },
      "outputs": [],
      "source": [
        "dog_probs = []\n",
        "run.model.eval()\n",
        "i=0\n",
        "with torch.no_grad():\n",
        "  for data, fileid in val_loader:\n",
        "      i+=1\n",
        "      if i>10:\n",
        "        break\n",
        "      data = data.to(device)\n",
        "      preds = run.model(data)\n",
        "      print(preds)\n",
        "      preds_list = F.softmax(preds, dim=1)[:, 1].tolist() #https://stats.stackexchange.com/questions/542054/why-does-torchvision-models-resnet18-not-use-softmax\n",
        "      dog_probs += list(zip(list(fileid), preds_list))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fqWJXRPTEBRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7Dqgtrjcp2a"
      },
      "source": [
        "# Future experiments\n",
        "1000 imgs set; or more intervals; saturate cheap experiments space.\n",
        "\n",
        "no test\n",
        "no random crop augmentation\n",
        "# Results\n",
        "\n",
        "batch=100, patience=7\n",
        "============\n",
        "\n",
        "2000 imgs train set,\n",
        "transforms.RandomResizedCrop(224,scale=(0.6, 1.0)), \n",
        "transforms.RandomHorizontalFlip(),\n",
        "transforms.ColorJitter(brightness=.4, hue=.15),\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)\n",
        "\n",
        "Best model scores: \n",
        " {'epoch': 33, 'epoch_train_accuracy': tensor(0.8380, device='cuda:0'), 'epoch_train_loss': tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.3896, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8188, device='cuda:0')}\n",
        "\n",
        "Training epoch 33: 100%|██████████| 20/20 [00:25<00:00,  1.30s/iteration, accuracy=tensor(83.8000, device='cuda:0'), loss=0.395]\n",
        "Epoch : 33, train accuracy : 0.8380000591278076, train loss : 0.3545871675014496\n",
        "100%|██████████| 50/50 [00:25<00:00,  1.93iteration/s, epoch_val_accuracy=tensor(0.8188, device='cuda:0'), val_loss=tensor(0.4697, device='cuda:0')]\n",
        "Epoch : 33, val_accuracy : 0.8188000321388245, val_loss : 0.3895597457885742\n",
        "New best model, min_val_loss: 0.3895597457885742\n",
        "\n",
        "\n",
        "\n",
        "================================================\n",
        "\n",
        "500 imgs train set,\n",
        "transforms.RandomResizedCrop(224,scale=(0.6, 1.0)), \n",
        "transforms.RandomHorizontalFlip(),\n",
        "transforms.ColorJitter(brightness=.4, hue=.15),\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)\n",
        "\n",
        "Best model scores: {'epoch': 39, 'epoch_train_accuracy': tensor(0.7480, device='cuda:0'), 'epoch_train_loss': tensor(0.5132, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.5940, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6928, device='cuda:0')}\n",
        "\n",
        "\n",
        "Training epoch 39: 100%|██████████| 5/5 [00:06<00:00,  1.27s/iteration, accuracy=tensor(74.8000, device='cuda:0'), loss=0.504]\n",
        "Epoch : 39, train accuracy : 0.7479999661445618, train loss : 0.5132189393043518\n",
        "100%|██████████| 50/50 [00:30<00:00,  1.65iteration/s, epoch_val_accuracy=tensor(0.6928, device='cuda:0'), val_loss=tensor(0.6708, device='cuda:0')]\n",
        "Epoch : 39, val_accuracy : 0.6927998661994934, val_loss : 0.5940383076667786\n",
        "New best model, min_val_loss: 0.5940383076667786\n",
        "100%|██████████| 50/50 [00:25<00:00,  1.93iteration/s, epoch_test_accuracy=tensor(0.6874, device='cuda:0'), test_loss=tensor(0.6752, device='cuda:0')]\n",
        "Epoch : 39, test_accuracy : 0.6873999238014221, test_loss : 0.5957822799682617\n",
        "\n",
        "================================================\n",
        "\n",
        "500 imgs train set,\n",
        "no transforms (only totensor)\n",
        "fails with wrong shapes\n",
        "\n",
        "================================================\n",
        "\n",
        "500 imgs train set, only 224 resize\n",
        " transforms.Resize((224, 224)),\n",
        "\n",
        "\n",
        " Best model scores: {'epoch': 2, 'epoch_train_accuracy': tensor(0.6660, device='cuda:0'), 'epoch_train_loss': tensor(0.6178, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6951, device='cuda:0'), 'epoch_val_accuracy': tensor(0.5774, device='cuda:0')}\n",
        "\n",
        "\n",
        " Training epoch 2: 100%|██████████| 5/5 [00:03<00:00,  1.28iteration/s, accuracy=tensor(66.6000, device='cuda:0'), loss=0.627]\n",
        "Epoch : 2, train accuracy : 0.6660000085830688, train loss : 0.6177714467048645\n",
        "100%|██████████| 50/50 [00:27<00:00,  1.85iteration/s, epoch_val_accuracy=tensor(0.5774, device='cuda:0'), val_loss=tensor(0.7848, device='cuda:0')]\n",
        "Epoch : 2, val_accuracy : 0.5773999691009521, val_loss : 0.6951212882995605\n",
        "New best model, min_val_loss: 0.6951212882995605\n",
        "100%|██████████| 50/50 [00:25<00:00,  1.95iteration/s, epoch_test_accuracy=tensor(0.5704, device='cuda:0'), test_loss=tensor(0.7834, device='cuda:0')]\n",
        "Epoch : 2, test_accuracy : 0.5703999996185303, test_loss : 0.6962302327156067\n",
        "\n",
        "note: patience in my implementation (> patience) means 8 more epochs get executed.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "========================================\n",
        "\n",
        "\n",
        "full train set\n",
        "\n",
        "\n",
        "Training epoch 40: 100%|██████████| 150/150 [03:28<00:00,  1.39s/iteration, accuracy=tensor(96.8067, device='cuda:0'), loss=0.0306]\n",
        "Epoch : 40, train accuracy : 0.9680668115615845, train loss : 0.07920999079942703\n",
        "100%|██████████| 50/50 [00:30<00:00,  1.65iteration/s, epoch_val_accuracy=tensor(0.9506, device='cuda:0'), val_loss=tensor(0.1377, device='cuda:0')]\n",
        "Epoch : 40, val_accuracy : 0.9506001472473145, val_loss : 0.12937913835048676\n",
        "New best model, min_val_loss: 0.12937913835048676\n",
        "100%|██████████| 50/50 [00:30<00:00,  1.66iteration/s, epoch_test_accuracy=tensor(0.9522, device='cuda:0'), test_loss=tensor(0.1373, device='cuda:0')]\n",
        "Epoch : 40, test_accuracy : 0.9522001147270203, test_loss : 0.12997546792030334\n",
        "\n",
        " Best model scores: {'epoch': 40, 'epoch_train_accuracy': tensor(0.9681, device='cuda:0'), 'epoch_train_loss': tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.1294, device='cuda:0'), 'epoch_val_accuracy': tensor(0.9506, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        " ============================== \n",
        "\n",
        " 4000 imgs\n",
        " \n",
        "\n",
        "Training epoch 56: 100%|██████████| 40/40 [00:50<00:00,  1.26s/iteration, accuracy=tensor(95.7750, device='cuda:0'), loss=0.112]\n",
        "Epoch : 56, train accuracy : 0.9577500224113464, train loss : 0.10647499561309814\n",
        "Validation after epoch 56: 100%|██████████| 50/50 [00:25<00:00,  1.94iteration/s, epoch_accuracy=tensor(0.8970, device='cuda:0'), loss=tensor(0.2677, device='cuda:0')]Epoch : 56, val_accuracy : 0.8970000147819519, val_loss : 0.26771894097328186\n",
        "epochs_since_min_loss 8\n",
        "Early stopping. \n",
        "\n",
        " Best model scores: {'epoch': 48, 'epoch_train_accuracy': tensor(0.9498, device='cuda:0'), 'epoch_train_loss': tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.2475, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8988, device='cuda:0')}\n",
        "\n",
        "\n",
        "  ============================== \n",
        "1000 imgs\n",
        "Training epoch 46: 100%|██████████| 10/10 [00:12<00:00,  1.25s/iteration, accuracy=tensor(82.7000, device='cuda:0'), loss=0.423]\n",
        "Epoch : 46, train accuracy : 0.8270000219345093, train loss : 0.3939513862133026\n",
        "Validation after epoch 46: 100%|██████████| 50/50 [00:26<00:00,  1.92iteration/s, epoch_accuracy=tensor(0.7390, device='cuda:0'), loss=tensor(0.5494, device='cuda:0')]Epoch : 46, val_accuracy : 0.7390000224113464, val_loss : 0.5493948459625244\n",
        "epochs_since_min_loss 8\n",
        "Early stopping. \n",
        "\n",
        " Best model scores: {'epoch': 38, 'epoch_train_accuracy': tensor(0.7650, device='cuda:0'), 'epoch_train_loss': tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.5249, device='cuda:0'), 'epoch_val_accuracy': tensor(0.7464, device='cuda:0')}\n",
        "\n",
        "[29]\n",
        "0s\n",
        "print(f\"Early stopping. \\n\\n Best model scores: {final_scores}\")\n",
        "Early stopping. \n",
        "\n",
        "=============================================\n",
        "\n",
        "300 train imgs\n",
        "\n",
        "\n",
        " Best model scores: {'epoch': 36, 'epoch_train_accuracy': tensor(0.7300, device='cuda:0'), 'epoch_train_loss': tensor(0.5215, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6209, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6694, device='cuda:0')}\n",
        "\n",
        "\n",
        " Training epoch 36: 100%|██████████| 3/3 [00:03<00:00,  1.25s/iteration, accuracy=tensor(73., device='cuda:0'), loss=0.505]\n",
        "Epoch : 36, train accuracy : 0.7300000190734863, train loss : 0.5214951038360596\n",
        "Validation after epoch 36: 100%|██████████| 50/50 [00:25<00:00,  1.93iteration/s, epoch_accuracy=tensor(0.6694, device='cuda:0'), loss=tensor(0.6209, device='cuda:0')]\n",
        "Epoch : 36, val_accuracy : 0.6693997979164124, val_loss : 0.6209338903427124\n",
        "New best model, min_val_loss: 0.6209338903427124\n",
        "\n",
        "\n",
        "\n",
        "===================================\n",
        "\n",
        "100 imgs train\n",
        "\n",
        "\n",
        "\n",
        " Best model scores: {'epoch': 26, 'epoch_train_accuracy': tensor(0.6100, device='cuda:0'), 'epoch_train_loss': tensor(0.6548, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6606, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6008, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " ========================\n",
        "\n",
        "\n",
        " 1000 imgs train \n",
        " no random crop\n",
        "\n",
        "\n",
        " Training epoch 11: 100%|██████████| 10/10 [00:13<00:00,  1.32s/iteration, accuracy=tensor(66.1000, device='cuda:0'), loss=0.598]\n",
        "Epoch : 11, train accuracy : 0.6610000133514404, train loss : 0.6124292612075806\n",
        "Validation after epoch 11: 100%|██████████| 50/50 [00:28<00:00,  1.78iteration/s, epoch_accuracy=tensor(0.6646, device='cuda:0'), loss=tensor(0.6104, device='cuda:0')]\n",
        "Epoch : 11, val_accuracy : 0.6645999550819397, val_loss : 0.6103843450546265\n",
        "New best model, min_val_loss: 0.6103843450546265\n",
        "\n",
        "\n",
        "=======\n",
        "\n",
        "4000 imgs no random crop\n",
        "\n",
        "Best model scores: {'epoch': 21, 'epoch_train_accuracy': tensor(0.8915, device='cuda:0'), 'epoch_train_loss': tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.4274, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8212, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "=======\n",
        "\n",
        "4000 imgs random crop (0.9, 1.0)\n",
        "\n",
        "\n",
        "\n",
        " Best model scores: {'epoch': 38, 'epoch_train_accuracy': tensor(0.9482, device='cuda:0'), 'epoch_train_loss': tensor(0.1189, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.3618, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8702, device='cuda:0')}\n",
        "\n",
        "\n",
        " =============\n",
        "\n",
        " 100 (0.9,1.0)\n",
        "\n",
        "\n",
        " \n",
        " Best model scores: {'epoch': 18, 'epoch_train_accuracy': tensor(0.6400, device='cuda:0'), 'epoch_train_loss': tensor(0.6298, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6644, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6080, device='cuda:0')}\n",
        "\n",
        " 99.9% sure it was actually 100 samples.\n",
        "\n",
        "\n",
        " ==================================\n",
        "\n",
        "300 (0.9,1.0)\n",
        "Best model scores: {'epoch': 13, 'epoch_train_accuracy': tensor(0.6600, device='cuda:0'), 'epoch_train_loss': tensor(0.6104, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6303, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6474, device='cuda:0')}\n",
        "\n",
        "==================================\n",
        "\n",
        "\n",
        "1000 (0.9, 1.0)\n",
        "\n",
        " Best model scores: {'epoch': 31, 'epoch_train_accuracy': tensor(0.7830, device='cuda:0'), 'epoch_train_loss': tensor(0.4721, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.5570, device='cuda:0'), 'epoch_val_accuracy': tensor(0.7226, device='cuda:0')}\n",
        "\n",
        "\n",
        " =========\n",
        "\n",
        "2000 0.9-1.0\n",
        "\n",
        "  Best model scores: {'epoch': 20, 'epoch_train_accuracy': tensor(0.7770, device='cuda:0'), 'epoch_train_loss': tensor(0.4572, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.5028, device='cuda:0'), 'epoch_val_accuracy': tensor(0.7600, device='cuda:0')}\n",
        "\n",
        "==========\n",
        "\n",
        "500 0.9-1.0\n",
        "\n",
        "Training epoch 11: 100%|██████████| 5/5 [00:06<00:00,  1.29s/iteration, accuracy=tensor(67.2000, device='cuda:0'), loss=0.631]\n",
        "Epoch : 11, train accuracy : 0.671999990940094, train loss : 0.623713493347168\n",
        "Validation after epoch 11: 100%|██████████| 50/50 [00:26<00:00,  1.91iteration/s, epoch_accuracy=tensor(0.6492, device='cuda:0'), loss=tensor(0.6313, device='cuda:0')]\n",
        "Epoch : 11, val_accuracy : 0.6492000222206116, val_loss : 0.6313157677650452\n",
        "New best model, min_val_loss: 0.6313157677650452\n",
        "\n",
        "\n",
        "\n",
        "==========\n",
        "\n",
        "500 0.9-1.0 + 200 bad crops\n",
        "\n",
        "Training epoch 19: 100%|██████████| 7/7 [00:08<00:00,  1.24s/iteration, accuracy=tensor(70.7143, device='cuda:0'), loss=0.569]\n",
        "\n",
        "Epoch : 19, train accuracy : 0.7071428894996643, train loss : 0.5531335473060608\n",
        "\n",
        "Validation after epoch 19: 100%|██████████| 50/50 [00:26<00:00,  1.90iteration/s, epoch_accuracy=tensor(0.6684, device='cuda:0'), loss=tensor(0.6105, device='cuda:0')]\n",
        "\n",
        "Epoch : 19, val_accuracy : 0.6683999300003052, val_loss : 0.6104905605316162\n",
        "New best model, min_val_loss: 0.6104905605316162\n",
        "\n",
        "=============\n",
        "\n",
        "1000 0.9-1.0 + 400 bad crops\n",
        "\n",
        "Best model scores: {'epoch': 32, 'epoch_train_accuracy': tensor(0.8057, device='cuda:0'), 'epoch_train_loss': tensor(0.4207, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.5650, device='cuda:0'), 'epoch_val_accuracy': tensor(0.7372, device='cuda:0')}\n",
        "\n",
        "Training epoch 32: 100%|██████████| 14/14 [00:18<00:00,  1.34s/iteration, accuracy=tensor(80.5714, device='cuda:0'), loss=0.399]\n",
        "\n",
        "Epoch : 32, train accuracy : 0.8057142496109009, train loss : 0.42074477672576904\n",
        "\n",
        "Validation after epoch 32: 100%|██████████| 50/50 [00:26<00:00,  1.90iteration/s, epoch_accuracy=tensor(0.7372, device='cuda:0'), loss=tensor(0.5650, device='cuda:0')]\n",
        "\n",
        "Epoch : 32, val_accuracy : 0.7372000217437744, val_loss : 0.56500244140625\n",
        "New best model, min_val_loss: 0.56500244140625\n",
        "\n",
        "========================\n",
        "\n",
        "\n",
        "100 0.9-1.0 + 40 bad crops\n",
        "\n",
        " Best model scores: {'epoch': 5, 'epoch_train_accuracy': tensor(0.5725, device='cuda:0'), 'epoch_train_loss': tensor(0.6900, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6688, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6106, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "==================\n",
        "\n",
        "4000 + 1600 bad crops\n",
        " Best model scores: {'epoch': 32, 'epoch_train_accuracy': tensor(0.8988, device='cuda:0'), 'epoch_train_loss': tensor(0.2333, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.3286, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8688, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "Training epoch 32: 100%|██████████| 56/56 [01:09<00:00,  1.24s/iteration, accuracy=tensor(89.8750, device='cuda:0'), loss=0.216]\n",
        "\n",
        "Epoch : 32, train accuracy : 0.898750364780426, train loss : 0.23328110575675964\n",
        "\n",
        "Validation after epoch 32: 100%|██████████| 50/50 [00:26<00:00,  1.92iteration/s, epoch_accuracy=tensor(0.8688, device='cuda:0'), loss=tensor(0.3286, device='cuda:0')]\n",
        "\n",
        "Epoch : 32, val_accuracy : 0.8687999248504639, val_loss : 0.32859963178634644\n",
        "New best model, min_val_loss: 0.32859963178634644\n",
        "\n",
        "\n",
        "=================================\n",
        "\n",
        "500 + 200 bad crops\n",
        "results SHOULD be the same as before, since bad crops got 0.0 and 1.0 labels respectively\n",
        "\n",
        "\n",
        "Training epoch 19: 100%|██████████| 7/7 [00:08<00:00,  1.21s/iteration, accuracy=tensor(69.0000, device='cuda:0'), loss=0.637]\n",
        "Epoch : 19, train accuracy : 0.6899999380111694, train loss : 0.5906238555908203\n",
        "Validation after epoch 19: 100%|██████████| 50/50 [00:26<00:00,  1.92iteration/s, epoch_accuracy=tensor(0.6570, device='cuda:0'), loss=tensor(0.6265, device='cuda:0')]\n",
        "Epoch : 19, val_accuracy : 0.6569998860359192, val_loss : 0.6265230774879456\n",
        "New best model, min_val_loss: 0.6265230774879456\n",
        "\n",
        "===============================\n",
        "\n",
        "500 + 200 bad crops, but 0.7 to 0.3 for bad crops\n",
        "\n",
        "Training epoch 29: 100%|██████████| 7/7 [00:08<00:00,  1.24s/iteration, accuracy=tensor(76.7143, device='cuda:0'), loss=0.529]\n",
        "Epoch : 29, train accuracy : 0.7671428918838501, train loss : 0.5189324617385864\n",
        "Validation after epoch 29: 100%|██████████| 50/50 [00:25<00:00,  1.96iteration/s, epoch_accuracy=tensor(0.6740, device='cuda:0'), loss=tensor(0.6259, device='cuda:0')]\n",
        "Epoch : 29, val_accuracy : 0.6739999651908875, val_loss : 0.625901997089386\n",
        "New best model, min_val_loss: 0.625901997089386\n",
        "\n",
        "\n",
        "==========================\n",
        "\n",
        "4000 + 1600 bad crops, but 0.7 to 0.3 for bad crops\n",
        "\n",
        "\n",
        "Training epoch 38: 100%|██████████| 56/56 [01:08<00:00,  1.22s/iteration, accuracy=tensor(89.8214, device='cuda:0'), loss=0.254]\n",
        "Epoch : 38, train accuracy : 0.8982144594192505, train loss : 0.2613590359687805\n",
        "Validation after epoch 38: 100%|██████████| 50/50 [00:25<00:00,  1.98iteration/s, epoch_accuracy=tensor(0.9016, device='cuda:0'), loss=tensor(0.2471, device='cuda:0')]\n",
        "Epoch : 38, val_accuracy : 0.9015999436378479, val_loss : 0.24705414474010468\n",
        "New best model, min_val_loss: 0.24705414474010468\n",
        "\n",
        "\n",
        "\n",
        "======================\n",
        "\n",
        "\n",
        "\n",
        "1000 + 400 bad crops, but 0.7 to 0.3 for bad crops\n",
        "\n",
        "\n",
        "Training epoch 40: 100%|██████████| 14/14 [00:18<00:00,  1.30s/iteration, accuracy=tensor(84.0714, device='cuda:0'), loss=0.44]\n",
        "\n",
        "Epoch : 40, train accuracy : 0.8407143354415894, train loss : 0.3932029604911804\n",
        "\n",
        "Validation after epoch 40: 100%|██████████| 50/50 [00:27<00:00,  1.79iteration/s, epoch_accuracy=tensor(0.7522, device='cuda:0'), loss=tensor(0.5355, device='cuda:0')]\n",
        "\n",
        "Epoch : 40, val_accuracy : 0.7521999478340149, val_loss : 0.5354558229446411\n",
        "New best model, min_val_loss: 0.5354558229446411\n",
        "\n",
        "\n",
        "\n",
        "Early stopping.  Best model scores: {'epoch': 40, 'epoch_train_accuracy': 0.8407, 'epoch_train_loss': 0.3932, 'epoch_val_loss': 0.5355, 'epoch_val_accuracy': 0.7522\n",
        "\n",
        "\n",
        "\n",
        "======================================\n",
        "\n",
        "\n",
        "100 + 40 bad crops, but 0.7 to 0.3 for bad crops\n",
        "\n",
        " Best model scores: {'epoch': 2, 'epoch_train_accuracy': tensor(0.5050, device='cuda:0'), 'epoch_train_loss': tensor(0.7095, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6726, device='cuda:0'), 'epoch_val_accuracy': tensor(0.5798, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "=======================================\n",
        "\n",
        "\n",
        "2000 + 800, 0.7/0.3\n",
        "\n",
        "subset_train_list = cats_list[:1000] + dogs_list[:1000] + bad_cats_generated_from_test_list[:400] + bad_dogs_generated_from_test_list[:400]\n",
        "\n",
        "\n",
        "Early stopping. \n",
        "\n",
        " Best model scores: {'epoch': 34, 'epoch_train_accuracy': tensor(0.8429, device='cuda:0'), 'epoch_train_loss': tensor(0.3801, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.4131, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8152, device='cuda:0')}\n",
        "\n",
        "\n",
        "==================\n",
        "\n",
        "2000 + 800 hard labels\n",
        "\n",
        "\n",
        "subset_train_list = cats_list[:1000] + dogs_list[:1000] + bad_cats_generated_from_test_list[:400] + bad_dogs_generated_from_test_list[:400]  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Early stopping. \n",
        "\n",
        " Best model scores: {'epoch': 29, 'epoch_train_accuracy': tensor(0.8254, device='cuda:0'), 'epoch_train_loss': tensor(0.3812, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.4917, device='cuda:0'), 'epoch_val_accuracy': tensor(0.7754, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "==============\n",
        "\n",
        "2000 + 400 50/50 concats\n",
        "\n",
        "\n",
        "Training epoch 28: 100%|██████████| 24/24 [00:29<00:00,  1.24s/iteration, accuracy=tensor(80.8333, device='cuda:0'), loss=0.314]\n",
        "Epoch : 28, train accuracy : 0.8083333373069763, train loss : 0.38290396332740784\n",
        "Validation after epoch 28: 100%|██████████| 50/50 [00:25<00:00,  1.99iteration/s, epoch_accuracy=tensor(0.8124, device='cuda:0'), loss=tensor(0.4261, device='cuda:0')]\n",
        "Epoch : 28, val_accuracy : 0.8123999238014221, val_loss : 0.4260599613189697\n",
        "New best model, min_val_loss: 0.4260599613189697\n",
        "\n",
        "\n",
        "Early stopping. \n",
        "\n",
        " Best model scores: {'epoch': 28, 'epoch_train_accuracy': tensor(0.8083, device='cuda:0'), 'epoch_train_loss': tensor(0.3829, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.4261, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8124, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "=============\n",
        "\n",
        "4000 + 800 0.5 0.5 concats\n",
        "\n",
        "Training epoch 26: 100%|██████████| 48/48 [01:02<00:00,  1.31s/iteration, accuracy=tensor(85.8958, device='cuda:0'), loss=0.217]\n",
        "Epoch : 26, train accuracy : 0.8589583039283752, train loss : 0.2704243063926697\n",
        "Validation after epoch 26: 100%|██████████| 50/50 [00:28<00:00,  1.77iteration/s, epoch_accuracy=tensor(0.8670, device='cuda:0'), loss=tensor(0.3314, device='cuda:0')]\n",
        "Epoch : 26, val_accuracy : 0.8670000433921814, val_loss : 0.33141279220581055\n",
        "New best model, min_val_loss: 0.33141279220581055\n",
        "\n",
        "\n",
        "==================\n",
        "\n",
        "\n",
        "1000 + 200 0.5 0.5 concat\n",
        "\n",
        "\n",
        "Training epoch 32: 100%|██████████| 12/12 [00:15<00:00,  1.32s/iteration, accuracy=tensor(76.7500, device='cuda:0'), loss=0.472]\n",
        "Epoch : 32, train accuracy : 0.7674999833106995, train loss : 0.4808453619480133\n",
        "Validation after epoch 32: 100%|██████████| 50/50 [00:28<00:00,  1.78iteration/s, epoch_accuracy=tensor(0.7368, device='cuda:0'), loss=tensor(0.5295, device='cuda:0')]\n",
        "Epoch : 32, val_accuracy : 0.7367998957633972, val_loss : 0.5294669270515442\n",
        "New best model, min_val_loss: 0.5294669270515442\n",
        "\n",
        "\n",
        "\n",
        "===========================\n",
        "\n",
        "1000 + 400 0.5 0.5 concat\n",
        "\n",
        "Training epoch 29: 100%|██████████| 14/14 [00:17<00:00,  1.23s/iteration, accuracy=tensor(73.0000, device='cuda:0'), loss=0.572]\n",
        "Epoch : 29, train accuracy : 0.7300000786781311, train loss : 0.5013352632522583\n",
        "Validation after epoch 29: 100%|██████████| 50/50 [00:26<00:00,  1.87iteration/s, epoch_accuracy=tensor(0.7268, device='cuda:0'), loss=tensor(0.5353, device='cuda:0')]\n",
        "Epoch : 29, val_accuracy : 0.7267997860908508, val_loss : 0.535283625125885\n",
        "New best model, min_val_loss: 0.535283625125885\n",
        "\n",
        "\n",
        "======================\n",
        "\n",
        "4000 + 1600 0.5 0.5 concat\n",
        "\n",
        "\n",
        "Training epoch 31: 100%|██████████| 56/56 [01:12<00:00,  1.29s/iteration, accuracy=tensor(82.5179, device='cuda:0'), loss=0.274]\n",
        "\n",
        "Epoch : 31, train accuracy : 0.8251785635948181, train loss : 0.30084556341171265\n",
        "\n",
        "Validation after epoch 31: 100%|██████████| 50/50 [00:28<00:00,  1.77iteration/s, epoch_accuracy=tensor(0.8682, device='cuda:0'), loss=tensor(0.3248, device='cuda:0')]\n",
        "\n",
        "Epoch : 31, val_accuracy : 0.8682000041007996, val_loss : 0.3248395025730133\n",
        "New best model, min_val_loss: 0.3248395025730133\n",
        "\n",
        "\n",
        "===========================\n",
        "\n",
        "\n",
        "100 + 40 0.5 0.5\n",
        "\n",
        "Training epoch 13: 100%|██████████| 2/2 [00:01<00:00,  1.08iteration/s, accuracy=tensor(52.5000, device='cuda:0'), loss=0.655]\n",
        "\n",
        "Epoch : 13, train accuracy : 0.5249999761581421, train loss : 0.6782363653182983\n",
        "\n",
        "Validation after epoch 13: 100%|██████████| 50/50 [00:28<00:00,  1.75iteration/s, epoch_accuracy=tensor(0.5844, device='cuda:0'), loss=tensor(0.6757, device='cuda:0')]\n",
        "\n",
        "Epoch : 13, val_accuracy : 0.584399938583374, val_loss : 0.6757243871688843\n",
        "New best model, min_val_loss: 0.6757243871688843\n",
        "\n",
        "\n",
        "\n",
        "====================\n",
        "\n",
        "\n",
        "500 + 200 0.5 0.5\n",
        "\n",
        "\n",
        "Training epoch 25: 100%|██████████| 7/7 [00:09<00:00,  1.34s/iteration, accuracy=tensor(65.7143, device='cuda:0'), loss=0.592]\n",
        "\n",
        "Epoch : 25, train accuracy : 0.6571428775787354, train loss : 0.5981876850128174\n",
        "\n",
        "Validation after epoch 25: 100%|██████████| 50/50 [00:28<00:00,  1.76iteration/s, epoch_accuracy=tensor(0.6582, device='cuda:0'), loss=tensor(0.6176, device='cuda:0')]\n",
        "\n",
        "Epoch : 25, val_accuracy : 0.6581999659538269, val_loss : 0.6176449060440063\n",
        "New best model, min_val_loss: 0.6176449060440063\n",
        "\n",
        "\n",
        "\n",
        "=================\n",
        "\n",
        "500 + 100 0.5 0.5\n",
        "\n",
        "Training epoch 22: 100%|██████████| 6/6 [00:07<00:00,  1.27s/iteration, accuracy=tensor(65., device='cuda:0'), loss=0.606]\n",
        "\n",
        "Epoch : 22, train accuracy : 0.6500000357627869, train loss : 0.6212294101715088\n",
        "\n",
        "Validation after epoch 22: 100%|██████████| 50/50 [00:28<00:00,  1.74iteration/s, epoch_accuracy=tensor(0.6530, device='cuda:0'), loss=tensor(0.6255, device='cuda:0')]\n",
        "\n",
        "Epoch : 22, val_accuracy : 0.6529998779296875, val_loss : 0.6254665851593018\n",
        "New best model, min_val_loss: 0.6254665851593018\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CvFx7AXZEOMMQSwMggEKbqKJU4_ogxUW",
      "authorship_tag": "ABX9TyNzl5gkZGGQ9h+TR0qD9Fxd",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}