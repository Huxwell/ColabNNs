{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huxwell/ColabNNs/blob/main/cats_n_dogs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0XYxT3MBckL"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import random # do random.seed(13) before every shuffle. order of shuffle() execution changes results order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMdiSs9-eB7j"
      },
      "source": [
        "Notes:\n",
        "- I have no labels for test here, so I am dropping 'test.zip' related code. I can split train into train, val, test; in fact I don't want to have a lot of examples for train set.\n",
        "- The sets are almost balanced, accuracy is ok here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGsOW96X9y6u"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JZRBEouz9xuT"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(13)\n",
        "if device =='cuda':\n",
        "    torch.cuda.manual_seed_all(13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kw2dMvob99Dd"
      },
      "outputs": [],
      "source": [
        "dataset_dir = '/content/drive/MyDrive/cats_n_dogs_unsure/dogs-vs-cats-redux-kernels-edition'\n",
        "os.listdir(dataset_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8slOqO8-IUw"
      },
      "outputs": [],
      "source": [
        "os.makedirs('local_data/', exist_ok=True)\n",
        "train_dir = 'local_data/train'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JytonT65-L6A"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile(os.path.join(dataset_dir, 'train.zip')) as train_zip:\n",
        "    train_zip.extractall('local_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzvXLys8CNY5"
      },
      "outputs": [],
      "source": [
        "os.listdir(train_dir)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCmaWu9nfx9V"
      },
      "outputs": [],
      "source": [
        "cats_list = sorted(glob.glob(os.path.join(train_dir,'cat*.jpg')))\n",
        "dogs_list = sorted(glob.glob(os.path.join(train_dir,'dog*.jpg')))\n",
        "print(len(cats_list))\n",
        "print(len(dogs_list))\n",
        "random.seed(13)\n",
        "random.shuffle(cats_list)\n",
        "random.seed(13) #multiple seed() executions are on purpose.\n",
        "random.shuffle(dogs_list)\n",
        "print(cats_list[:3])\n",
        "print(dogs_list[:3])\n",
        "# some sanity check to make sure no uncontrolled randomness beyond this point\n",
        "assert cats_list[2] == 'local_data/train/cat.801.jpg'\n",
        "assert dogs_list[2] == 'local_data/train/dog.801.jpg'\n",
        "assert len(cats_list) == len(dogs_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADT-iYGCiOMg"
      },
      "outputs": [],
      "source": [
        "full_train_list = cats_list[:7500] + dogs_list[:7500]\n",
        "# subset_train_list = cats_list[:500] + dogs_list[:500]\n",
        "subset_train_list = cats_list[:2000] + dogs_list[:2000]\n",
        "# subset_train_list = cats_list[:250] + dogs_list[:250]\n",
        "# subset_train_list = cats_list[:150] + dogs_list[:150]\n",
        "# subset_train_list = cats_list[:50] + dogs_list[:50]\n",
        "val_list = cats_list[7500:10000] + dogs_list[7500:10000]\n",
        "test_list = cats_list[10000:] + dogs_list[10000:]\n",
        "print(len(subset_train_list),len(full_train_list), len(val_list), len(test_list))\n",
        "\n",
        "random.seed(13)\n",
        "random.shuffle(full_train_list)\n",
        "random.seed(13)\n",
        "random.shuffle(subset_train_list)\n",
        "random.seed(13)\n",
        "random.shuffle(val_list)\n",
        "random.seed(13)\n",
        "random.shuffle(test_list)\n",
        "print(\"full\",full_train_list[:9])\n",
        "print(\"subset\",subset_train_list[:9])\n",
        "print(\"val\",val_list[:9])\n",
        "print(\"test\",test_list[:9])\n",
        "assert full_train_list[4] == 'local_data/train/cat.1612.jpg'\n",
        "# assert subset_train_list[4] == 'local_data/train/cat.1787.jpg' #500imgs train\n",
        "assert subset_train_list[4] == 'local_data/train/cat.5360.jpg' #4000 imgs train\n",
        "# assert subset_train_list[4] == 'local_data/train/dog.445.jpg' # 1000 imgs train\n",
        "# assert subset_train_list[4] == 'local_data/train/dog.7661.jpg' # 300 imgs\n",
        "# assert subset_train_list[4] == 'local_data/train/cat.9914.jpg' #100 imgs\n",
        "# assert subset_train_list[4] == 'local_data/train/dog.11151.jpg'#2000imgs train\n",
        "assert val_list[4] == 'local_data/train/dog.12023.jpg'\n",
        "assert test_list[4] == 'local_data/train/dog.6485.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_iriJP1lzl4"
      },
      "outputs": [],
      "source": [
        "train_list = subset_train_list # 5 batches # or 20 batches\n",
        "# train_list = full_train_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgRVni0iCVkg"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1313131313)\n",
        "random_idx = np.random.randint(1,len(train_list),size=10)\n",
        "print(random_idx)\n",
        "fig = plt.figure(figsize=(20., 10.))\n",
        "\n",
        "for i, img_idx in enumerate(random_idx):\n",
        "    ax = fig.add_subplot(2,5,i+1)\n",
        "    img = Image.open(train_list[img_idx])\n",
        "    plt.imshow(img)\n",
        "    i+=1\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSk64R7gDGsz"
      },
      "outputs": [],
      "source": [
        "train_list[0].split('/')[-1].split('.')[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpFt-8n8DgfT"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM5LfbFcDf_Y"
      },
      "outputs": [],
      "source": [
        "train_transforms =  transforms.Compose([ #these params work well for cats & dogs.:\n",
        "  # transforms.Resize((224, 224)),\n",
        "  transforms.RandomResizedCrop(224,scale=(0.9, 1.0)), \n",
        "  transforms.RandomHorizontalFlip(),\n",
        "  transforms.ColorJitter(brightness=.4, hue=.15),\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "val_transforms = transforms.Compose([\n",
        "  transforms.Resize((224, 224)),\n",
        "  # transforms.RandomResizedCrop(224),\n",
        "  # transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([   \n",
        "  transforms.Resize((224, 224)),\n",
        "  # transforms.RandomResizedCrop(224),\n",
        "  # transforms.RandomHorizontalFlip(),\n",
        "  transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-TsOoMoDsur"
      },
      "outputs": [],
      "source": [
        "class dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,file_list,transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        \n",
        "    #dataset length\n",
        "    def __len__(self):\n",
        "        self.filelength = len(self.file_list)\n",
        "        return self.filelength\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        img = Image.open(img_path)\n",
        "        img_transformed = self.transform(img)\n",
        "        \n",
        "        label = img_path.split('/')[-1].split('.')[0]\n",
        "        if label == 'dog':\n",
        "            label=1\n",
        "        elif label == 'cat':\n",
        "            label=0\n",
        "            \n",
        "        return img_transformed,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "936yLEVWDyc9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrrBRLdwbIDR"
      },
      "outputs": [],
      "source": [
        "## Visualization of Image Classification \n",
        "import torchvision\n",
        "def visualize_classification(loader_iter, nrofItems = 9, pad = 0) -> None:\n",
        "\n",
        "  #Iterate through the data loader\n",
        "  imgTensor, labels = next(loader_iter)\n",
        "  labels = labels.tolist()\n",
        "\n",
        "  # Generate image grid\n",
        "  grid = torchvision.utils.make_grid(imgTensor[:nrofItems], padding = pad, nrow=nrofItems)\n",
        "\n",
        "  # Permute the axis as numpy expects image of shape (H x W x C) \n",
        "  grid = grid.permute(1, 2, 0)\n",
        "  \n",
        "  # Set up plot config\n",
        "  plt.figure(figsize=(8, 2), dpi=300)\n",
        "  plt.axis('off')\n",
        "\n",
        "  # Plot Image Grid\n",
        "  plt.imshow(grid)\n",
        "  \n",
        "  # # Plot the image titles\n",
        "  # fact = 1 + (nrofItems)/100\n",
        "  # rng = np.linspace(1/(fact*nrofItems), 1 - 1/(fact*nrofItems) , num = nrofItems)\n",
        "  # for idx, val in enumerate(rng):\n",
        "  #   plt.figtext(val, 0.85, labels[idx], fontsize=8)\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8koteIep9wIW"
      },
      "outputs": [],
      "source": [
        "batch_size = 100 # we will use mini-batch method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ2krjGVDzuk"
      },
      "outputs": [],
      "source": [
        "train_data = dataset(train_list, transform=train_transforms)\n",
        "val_data = dataset(val_list, transform=val_transforms)\n",
        "test_data = dataset(test_list, transform=test_transforms)\n",
        "visualise_train_dataset = dataset(train_list, transform=train_transforms)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=False )\n",
        "val_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=batch_size, shuffle=False)\n",
        "test_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=batch_size, shuffle=False)\n",
        "vis_train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=10, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Iy8VyU1gqkD"
      },
      "outputs": [],
      "source": [
        "# this cell is here only because the Author apprently didn't understand how Dataset and Dataloaders behave - are they iterable, are they generators? - well they are hybrid. - , and wanted to see what happens\n",
        "# all but one cell can be commented\n",
        "# TODO: you don't need a separate loader. each iteration goes from the beginning\n",
        "# but its interesting that different augmentations get generated.\n",
        "iterator = iter(vis_train_loader)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iter(vis_train_loader))\n",
        "visualize_classification(iter(vis_train_loader))\n",
        "visualize_classification(iter(vis_train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5cCbNTRkppr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWizETdhD1h0"
      },
      "outputs": [],
      "source": [
        "print(len(train_data), len(train_loader), len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAfRCxgVbseH"
      },
      "outputs": [],
      "source": [
        "print(sum(1 for filename in train_data.file_list if 'cat' in filename))\n",
        "print(sum(1 for filename in train_data.file_list if 'dog' in filename))\n",
        "print(sum(1 for filename in val_data.file_list if 'cat' in filename))\n",
        "print(sum(1 for filename in val_data.file_list if 'dog' in filename))\n",
        "print(sum(1 for filename in test_data.file_list if 'cat' in filename))\n",
        "print(sum(1 for filename in test_data.file_list if 'dog' in filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v2wAJjCD3Ip"
      },
      "outputs": [],
      "source": [
        "#check our images shape\n",
        "train_data[0][0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yr6yCrKsU8P"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81GkYD0_D6ZM"
      },
      "outputs": [],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDZjG9EbES1K"
      },
      "outputs": [],
      "source": [
        "model = model.to(device)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE4uuPYWEbsE"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.Adam(params = model.parameters(),lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpQD81gpk6yE"
      },
      "outputs": [],
      "source": [
        "def eval_model(loader: torch.utils.data.dataloader.DataLoader, model: nn.Module, description: str=\"Evaluation:\") -> tuple: #[torch.Tensor, torch.Tensor] detailed tuple types only in Python >3.9, colab has 3.8.16\n",
        "  epoch_accuracy=0\n",
        "  epoch_loss =0\n",
        "  with torch.no_grad():\n",
        "    with tqdm(loader, unit=\"iteration\") as tqdm_wrapped_loader:\n",
        "      tqdm_wrapped_loader.set_description(description)\n",
        "      for data, label in tqdm_wrapped_loader:\n",
        "          data = data.to(device)\n",
        "          label = label.to(device)\n",
        "\n",
        "          output = model(data)\n",
        "          loss = criterion(output,label)\n",
        "\n",
        "\n",
        "          acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "          epoch_accuracy += acc/ len(loader)\n",
        "          epoch_loss += loss/ len(loader)\n",
        "          tqdm_wrapped_loader.set_postfix(epoch_accuracy=epoch_accuracy, loss=epoch_loss)\n",
        "  return epoch_accuracy, epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvkN7MXIEjTn"
      },
      "outputs": [],
      "source": [
        "epochs = 100 #10\n",
        "min_val_loss = float('inf')\n",
        "epochs_since_min_loss = 0\n",
        "patience = 7\n",
        "final_scores = {}\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\n\",\"=\"*30,\"\\n\")\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    \n",
        "    with tqdm(train_loader, unit=\"iteration\") as tepoch:\n",
        "      \n",
        "      for data, label in tepoch:\n",
        "          tepoch.set_description(f\"Training epoch {epoch}\")\n",
        "          data = data.to(device)\n",
        "          label = label.to(device)\n",
        "          \n",
        "          output = model(data)\n",
        "          loss = criterion(output, label)\n",
        "          \n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "          acc = ((output.argmax(dim=1) == label).float().mean())\n",
        "          epoch_accuracy += acc/len(train_loader)\n",
        "          epoch_loss += loss/len(train_loader)\n",
        "          tepoch.set_postfix(loss=loss.item(), accuracy=100. * epoch_accuracy)\n",
        "      print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch, epoch_accuracy,epoch_loss))\n",
        "\n",
        "    \n",
        "      # with torch.no_grad():\n",
        "      #     epoch_val_accuracy=0\n",
        "      #     epoch_val_loss =0\n",
        "      #     with tqdm(val_loader, unit=\"iteration\") as tqdm_wrapped_valid_loader:\n",
        "      #       tepoch.set_description(f\"Validation after epoch {epoch}\")\n",
        "      #       for data, label in tqdm_wrapped_valid_loader:\n",
        "      #           data = data.to(device)\n",
        "      #           label = label.to(device)\n",
        "                \n",
        "      #           val_output = model(data)\n",
        "      #           val_loss = criterion(val_output,label)\n",
        "                \n",
        "                \n",
        "      #           acc = ((val_output.argmax(dim=1) == label).float().mean())\n",
        "      #           epoch_val_accuracy += acc/ len(val_loader)\n",
        "      #           epoch_val_loss += val_loss/ len(val_loader)\n",
        "      #           tqdm_wrapped_valid_loader.set_postfix(epoch_val_accuracy=epoch_val_accuracy, val_loss=val_loss)\n",
        "    epoch_val_accuracy,epoch_val_loss = eval_model(val_loader, model, f\"Validation after epoch {epoch}\")\n",
        "    print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch, epoch_val_accuracy,epoch_val_loss))\n",
        "    scalar_val_loss = epoch_val_loss.item()\n",
        "    if scalar_val_loss < min_val_loss:\n",
        "      min_val_loss = scalar_val_loss \n",
        "      epochs_since_min_loss = 0 \n",
        "      final_scores['epoch']=epoch\n",
        "      final_scores['epoch_train_accuracy']=epoch_accuracy\n",
        "      final_scores['epoch_train_loss']=epoch_loss\n",
        "      final_scores['epoch_val_loss']=epoch_val_loss\n",
        "      final_scores['epoch_val_accuracy']=epoch_val_accuracy\n",
        "\n",
        "\n",
        "      print(\"New best model, min_val_loss:\", min_val_loss)\n",
        "\n",
        "\n",
        "      # with torch.no_grad():\n",
        "      #     epoch_test_accuracy=0\n",
        "      #     epoch_test_loss =0\n",
        "      #     with tqdm(test_loader, unit=\"iteration\") as tqdm_wrapped_test_loader:\n",
        "      #       tepoch.set_description(f\"Test after epoch {epoch}\")\n",
        "      #       for data, label in tqdm_wrapped_test_loader:\n",
        "      #           data = data.to(device)\n",
        "      #           label = label.to(device)\n",
        "                \n",
        "      #           test_output = model(data)\n",
        "      #           test_loss = criterion(test_output,label)\n",
        "                \n",
        "                \n",
        "      #           acc = ((test_output.argmax(dim=1) == label).float().mean())\n",
        "      #           epoch_test_accuracy += acc/ len(test_loader)\n",
        "      #           epoch_test_loss += test_loss/ len(test_loader)\n",
        "      #           tqdm_wrapped_test_loader.set_postfix(epoch_test_accuracy=epoch_test_accuracy, test_loss=test_loss)\n",
        "\n",
        "      # epoch_test_accuracy,epoch_test_loss = eval_model(test_loader, model, f\"Test after epoch {epoch}\")\n",
        "      # print('Epoch : {}, test_accuracy : {}, test_loss : {}'.format(epoch, epoch_test_accuracy,epoch_test_loss))\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "      epochs_since_min_loss+=1\n",
        "      print(\"epochs_since_min_loss\",epochs_since_min_loss)\n",
        "    if epochs_since_min_loss > patience:\n",
        "      print(f\"Early stopping. \\n\\n Best model scores: {final_scores}\")\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_FB6xAMBki3"
      },
      "outputs": [],
      "source": [
        "print(f\"Early stopping. \\n\\n Best model scores: {final_scores}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGb3zoqwEmWl"
      },
      "outputs": [],
      "source": [
        "dog_probs = []\n",
        "model.eval()\n",
        "i=0\n",
        "with torch.no_grad():b\n",
        "  for data, fileid in val_loader:\n",
        "      i+=1\n",
        "      if i>10:\n",
        "        break\n",
        "      data = data.to(device)\n",
        "      preds = model(data)\n",
        "      print(preds)\n",
        "      preds_list = F.softmax(preds, dim=1)[:, 1].tolist() #https://stats.stackexchange.com/questions/542054/why-does-torchvision-models-resnet18-not-use-softmax\n",
        "      dog_probs += list(zip(list(fileid), preds_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7Dqgtrjcp2a"
      },
      "source": [
        "# Future experiments\n",
        "1000 imgs set; or more intervals; saturate cheap experiments space.\n",
        "\n",
        "no test\n",
        "no random crop augmentation\n",
        "# Results\n",
        "\n",
        "batch=100, patience=7\n",
        "============\n",
        "\n",
        "2000 imgs train set,\n",
        "transforms.RandomResizedCrop(224,scale=(0.6, 1.0)), \n",
        "transforms.RandomHorizontalFlip(),\n",
        "transforms.ColorJitter(brightness=.4, hue=.15),\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)\n",
        "\n",
        "Best model scores: \n",
        " {'epoch': 33, 'epoch_train_accuracy': tensor(0.8380, device='cuda:0'), 'epoch_train_loss': tensor(0.3546, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.3896, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8188, device='cuda:0')}\n",
        "\n",
        "Training epoch 33: 100%|██████████| 20/20 [00:25<00:00,  1.30s/iteration, accuracy=tensor(83.8000, device='cuda:0'), loss=0.395]\n",
        "Epoch : 33, train accuracy : 0.8380000591278076, train loss : 0.3545871675014496\n",
        "100%|██████████| 50/50 [00:25<00:00,  1.93iteration/s, epoch_val_accuracy=tensor(0.8188, device='cuda:0'), val_loss=tensor(0.4697, device='cuda:0')]\n",
        "Epoch : 33, val_accuracy : 0.8188000321388245, val_loss : 0.3895597457885742\n",
        "New best model, min_val_loss: 0.3895597457885742\n",
        "\n",
        "\n",
        "\n",
        "================================================\n",
        "\n",
        "500 imgs train set,\n",
        "transforms.RandomResizedCrop(224,scale=(0.6, 1.0)), \n",
        "transforms.RandomHorizontalFlip(),\n",
        "transforms.ColorJitter(brightness=.4, hue=.15),\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=False)\n",
        "\n",
        "Best model scores: {'epoch': 39, 'epoch_train_accuracy': tensor(0.7480, device='cuda:0'), 'epoch_train_loss': tensor(0.5132, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.5940, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6928, device='cuda:0')}\n",
        "\n",
        "\n",
        "Training epoch 39: 100%|██████████| 5/5 [00:06<00:00,  1.27s/iteration, accuracy=tensor(74.8000, device='cuda:0'), loss=0.504]\n",
        "Epoch : 39, train accuracy : 0.7479999661445618, train loss : 0.5132189393043518\n",
        "100%|██████████| 50/50 [00:30<00:00,  1.65iteration/s, epoch_val_accuracy=tensor(0.6928, device='cuda:0'), val_loss=tensor(0.6708, device='cuda:0')]\n",
        "Epoch : 39, val_accuracy : 0.6927998661994934, val_loss : 0.5940383076667786\n",
        "New best model, min_val_loss: 0.5940383076667786\n",
        "100%|██████████| 50/50 [00:25<00:00,  1.93iteration/s, epoch_test_accuracy=tensor(0.6874, device='cuda:0'), test_loss=tensor(0.6752, device='cuda:0')]\n",
        "Epoch : 39, test_accuracy : 0.6873999238014221, test_loss : 0.5957822799682617\n",
        "\n",
        "================================================\n",
        "\n",
        "500 imgs train set,\n",
        "no transforms (only totensor)\n",
        "fails with wrong shapes\n",
        "\n",
        "================================================\n",
        "\n",
        "500 imgs train set, only 224 resize\n",
        " transforms.Resize((224, 224)),\n",
        "\n",
        "\n",
        " Best model scores: {'epoch': 2, 'epoch_train_accuracy': tensor(0.6660, device='cuda:0'), 'epoch_train_loss': tensor(0.6178, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6951, device='cuda:0'), 'epoch_val_accuracy': tensor(0.5774, device='cuda:0')}\n",
        "\n",
        "\n",
        " Training epoch 2: 100%|██████████| 5/5 [00:03<00:00,  1.28iteration/s, accuracy=tensor(66.6000, device='cuda:0'), loss=0.627]\n",
        "Epoch : 2, train accuracy : 0.6660000085830688, train loss : 0.6177714467048645\n",
        "100%|██████████| 50/50 [00:27<00:00,  1.85iteration/s, epoch_val_accuracy=tensor(0.5774, device='cuda:0'), val_loss=tensor(0.7848, device='cuda:0')]\n",
        "Epoch : 2, val_accuracy : 0.5773999691009521, val_loss : 0.6951212882995605\n",
        "New best model, min_val_loss: 0.6951212882995605\n",
        "100%|██████████| 50/50 [00:25<00:00,  1.95iteration/s, epoch_test_accuracy=tensor(0.5704, device='cuda:0'), test_loss=tensor(0.7834, device='cuda:0')]\n",
        "Epoch : 2, test_accuracy : 0.5703999996185303, test_loss : 0.6962302327156067\n",
        "\n",
        "note: patience in my implementation (> patience) means 8 more epochs get executed.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "========================================\n",
        "\n",
        "\n",
        "full train set\n",
        "\n",
        "\n",
        "Training epoch 40: 100%|██████████| 150/150 [03:28<00:00,  1.39s/iteration, accuracy=tensor(96.8067, device='cuda:0'), loss=0.0306]\n",
        "Epoch : 40, train accuracy : 0.9680668115615845, train loss : 0.07920999079942703\n",
        "100%|██████████| 50/50 [00:30<00:00,  1.65iteration/s, epoch_val_accuracy=tensor(0.9506, device='cuda:0'), val_loss=tensor(0.1377, device='cuda:0')]\n",
        "Epoch : 40, val_accuracy : 0.9506001472473145, val_loss : 0.12937913835048676\n",
        "New best model, min_val_loss: 0.12937913835048676\n",
        "100%|██████████| 50/50 [00:30<00:00,  1.66iteration/s, epoch_test_accuracy=tensor(0.9522, device='cuda:0'), test_loss=tensor(0.1373, device='cuda:0')]\n",
        "Epoch : 40, test_accuracy : 0.9522001147270203, test_loss : 0.12997546792030334\n",
        "\n",
        " Best model scores: {'epoch': 40, 'epoch_train_accuracy': tensor(0.9681, device='cuda:0'), 'epoch_train_loss': tensor(0.0792, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.1294, device='cuda:0'), 'epoch_val_accuracy': tensor(0.9506, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        " ============================== \n",
        " \n",
        " 4000 imgs\n",
        " \n",
        "\n",
        "Training epoch 56: 100%|██████████| 40/40 [00:50<00:00,  1.26s/iteration, accuracy=tensor(95.7750, device='cuda:0'), loss=0.112]\n",
        "Epoch : 56, train accuracy : 0.9577500224113464, train loss : 0.10647499561309814\n",
        "Validation after epoch 56: 100%|██████████| 50/50 [00:25<00:00,  1.94iteration/s, epoch_accuracy=tensor(0.8970, device='cuda:0'), loss=tensor(0.2677, device='cuda:0')]Epoch : 56, val_accuracy : 0.8970000147819519, val_loss : 0.26771894097328186\n",
        "epochs_since_min_loss 8\n",
        "Early stopping. \n",
        "\n",
        " Best model scores: {'epoch': 48, 'epoch_train_accuracy': tensor(0.9498, device='cuda:0'), 'epoch_train_loss': tensor(0.1290, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.2475, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8988, device='cuda:0')}\n",
        "\n",
        "\n",
        "  ============================== \n",
        "1000 imgs\n",
        "Training epoch 46: 100%|██████████| 10/10 [00:12<00:00,  1.25s/iteration, accuracy=tensor(82.7000, device='cuda:0'), loss=0.423]\n",
        "Epoch : 46, train accuracy : 0.8270000219345093, train loss : 0.3939513862133026\n",
        "Validation after epoch 46: 100%|██████████| 50/50 [00:26<00:00,  1.92iteration/s, epoch_accuracy=tensor(0.7390, device='cuda:0'), loss=tensor(0.5494, device='cuda:0')]Epoch : 46, val_accuracy : 0.7390000224113464, val_loss : 0.5493948459625244\n",
        "epochs_since_min_loss 8\n",
        "Early stopping. \n",
        "\n",
        " Best model scores: {'epoch': 38, 'epoch_train_accuracy': tensor(0.7650, device='cuda:0'), 'epoch_train_loss': tensor(0.4642, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.5249, device='cuda:0'), 'epoch_val_accuracy': tensor(0.7464, device='cuda:0')}\n",
        "\n",
        "[29]\n",
        "0s\n",
        "print(f\"Early stopping. \\n\\n Best model scores: {final_scores}\")\n",
        "Early stopping. \n",
        "\n",
        "=============================================\n",
        "\n",
        "300 train imgs\n",
        "\n",
        "\n",
        " Best model scores: {'epoch': 36, 'epoch_train_accuracy': tensor(0.7300, device='cuda:0'), 'epoch_train_loss': tensor(0.5215, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6209, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6694, device='cuda:0')}\n",
        "\n",
        "\n",
        " Training epoch 36: 100%|██████████| 3/3 [00:03<00:00,  1.25s/iteration, accuracy=tensor(73., device='cuda:0'), loss=0.505]\n",
        "Epoch : 36, train accuracy : 0.7300000190734863, train loss : 0.5214951038360596\n",
        "Validation after epoch 36: 100%|██████████| 50/50 [00:25<00:00,  1.93iteration/s, epoch_accuracy=tensor(0.6694, device='cuda:0'), loss=tensor(0.6209, device='cuda:0')]\n",
        "Epoch : 36, val_accuracy : 0.6693997979164124, val_loss : 0.6209338903427124\n",
        "New best model, min_val_loss: 0.6209338903427124\n",
        "\n",
        "\n",
        "\n",
        "===================================\n",
        "\n",
        "100 imgs train\n",
        "\n",
        "\n",
        "\n",
        " Best model scores: {'epoch': 26, 'epoch_train_accuracy': tensor(0.6100, device='cuda:0'), 'epoch_train_loss': tensor(0.6548, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.6606, device='cuda:0'), 'epoch_val_accuracy': tensor(0.6008, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " ========================\n",
        "\n",
        "\n",
        " 1000 imgs train \n",
        " no random crop\n",
        "\n",
        "\n",
        " Training epoch 11: 100%|██████████| 10/10 [00:13<00:00,  1.32s/iteration, accuracy=tensor(66.1000, device='cuda:0'), loss=0.598]\n",
        "Epoch : 11, train accuracy : 0.6610000133514404, train loss : 0.6124292612075806\n",
        "Validation after epoch 11: 100%|██████████| 50/50 [00:28<00:00,  1.78iteration/s, epoch_accuracy=tensor(0.6646, device='cuda:0'), loss=tensor(0.6104, device='cuda:0')]\n",
        "Epoch : 11, val_accuracy : 0.6645999550819397, val_loss : 0.6103843450546265\n",
        "New best model, min_val_loss: 0.6103843450546265\n",
        "\n",
        "\n",
        "=======\n",
        "\n",
        "4000 imgs no random crop\n",
        "\n",
        "Best model scores: {'epoch': 21, 'epoch_train_accuracy': tensor(0.8915, device='cuda:0'), 'epoch_train_loss': tensor(0.2574, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.4274, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8212, device='cuda:0')}\n",
        "\n",
        "\n",
        "\n",
        "=======\n",
        "\n",
        "4000 imgs tandom crop (0.9, 1.0)\n",
        "\n",
        "\n",
        "\n",
        " Best model scores: {'epoch': 38, 'epoch_train_accuracy': tensor(0.9482, device='cuda:0'), 'epoch_train_loss': tensor(0.1189, device='cuda:0', grad_fn=<AddBackward0>), 'epoch_val_loss': tensor(0.3618, device='cuda:0'), 'epoch_val_accuracy': tensor(0.8702, device='cuda:0')}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1CvFx7AXZEOMMQSwMggEKbqKJU4_ogxUW",
      "authorship_tag": "ABX9TyP//fywaB2dJC64j1gFS5Hh",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}