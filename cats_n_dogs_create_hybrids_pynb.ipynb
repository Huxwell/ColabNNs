{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LcayOEqcRPyJV-ZvrtZKxYaLMAeadUPg",
      "authorship_tag": "ABX9TyO1i4pPlXvtngkorxgavCUz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huxwell/ColabNNs/blob/main/cats_n_dogs_create_hybrids_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This code was used to generate the bad-crop dataset\n",
        "It used:\n",
        "*   transforms.RandomResizedCrop(224,scale=(0.2, 0.4))\n",
        "*   test_list = cats_list[10000:] + dogs_list[10000:]\n",
        "*   assert test_list[4] == 'local_data/train/dog.6485.jpg'\n",
        "*   4 epochs\n",
        "*   long and tedious process of manually going through generated imgs and removing good-quality crops\n",
        "*   I am not proud of this process, probally should have used yolo or some other detector for this\n",
        "*   Got up to dog.4998_crop_e_3.jpg, with 1866 dog imgs left\n",
        "*   Got up to cat.6996_crop_e_3.jpg, with 1866 cat imgs left\n",
        "*   I don't want to refactor this, this spaghetti has served its purpose.\n",
        "*   I keep the results at drive/cats_n_dogs_unsure/cat_dogs_crops_from_test_20k_filtered.zip\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rMaX6S74HXHD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9rdrEeIbICl"
      },
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "import torch\n",
        "# import torch.optim as optim\n",
        "# import torch.nn.functional as F\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "# import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import glob\n",
        "# from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import random # do random.seed(13) before every shuffle. order of shuffle() execution changes results order."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = '/content/drive/MyDrive/cats_n_dogs_unsure/dogs-vs-cats-redux-kernels-edition'\n",
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "id": "lSga2d5abUSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('local_data/', exist_ok=True)\n",
        "train_dir = 'local_data/train'"
      ],
      "metadata": {
        "id": "rVma9140hRSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!ls /content/local_data/train\n"
      ],
      "metadata": {
        "id": "EVY9Mlp-hbJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(os.path.join(dataset_dir, 'train.zip')) as train_zip:\n",
        "    train_zip.extractall('local_data')"
      ],
      "metadata": {
        "id": "n83YpV5LbVvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(train_dir)[:5]"
      ],
      "metadata": {
        "id": "XiwerW2UbY3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats_list = sorted(glob.glob(os.path.join(train_dir,'cat*.jpg')))\n",
        "dogs_list = sorted(glob.glob(os.path.join(train_dir,'dog*.jpg')))\n",
        "print(len(cats_list))\n",
        "print(len(dogs_list))\n",
        "random.seed(13)\n",
        "random.shuffle(cats_list)\n",
        "random.seed(13) #multiple seed() executions are on purpose.\n",
        "random.shuffle(dogs_list)\n",
        "print(cats_list[:3])\n",
        "print(dogs_list[:3])\n",
        "# some sanity check to make sure no uncontrolled randomness beyond this point\n",
        "assert cats_list[2] == 'local_data/train/cat.801.jpg'\n",
        "assert dogs_list[2] == 'local_data/train/dog.801.jpg'\n",
        "assert len(cats_list) == len(dogs_list)\n"
      ],
      "metadata": {
        "id": "l0Fd8HBpbaRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_train_list = cats_list[:7500] + dogs_list[:7500]\n",
        "subset_train_list = cats_list[:2000] + dogs_list[:2000]\n",
        "# subset_train_list = cats_list[:250] + dogs_list[:250]\n",
        "val_list = cats_list[7500:10000] + dogs_list[7500:10000]\n",
        "test_list = cats_list[10000:] + dogs_list[10000:]\n",
        "print(len(full_train_list), len(val_list), len(test_list))\n",
        "\n",
        "random.seed(13)\n",
        "random.shuffle(full_train_list)\n",
        "random.seed(13)\n",
        "random.shuffle(subset_train_list)\n",
        "random.seed(13)\n",
        "random.shuffle(val_list)\n",
        "random.seed(13)\n",
        "random.shuffle(test_list)\n",
        "print(\"full\",full_train_list[:9])\n",
        "print(\"subset\",subset_train_list[:9])\n",
        "print(\"val\",val_list[:9])\n",
        "print(\"test\",test_list[:9])\n",
        "assert full_train_list[4] == 'local_data/train/cat.1612.jpg'\n",
        "# assert subset_train_list[4] == 'local_data/train/cat.1787.jpg' #500imgs train\n",
        "assert subset_train_list[4] == 'local_data/train/cat.5360.jpg' #4000 imgs train\n",
        "# assert subset_train_list[4] == 'local_data/train/dog.11151.jpg'#2000imgs train\n",
        "assert val_list[4] == 'local_data/train/dog.12023.jpg'\n",
        "assert test_list[4] == 'local_data/train/dog.6485.jpg'"
      ],
      "metadata": {
        "id": "YbU7_Nwdg3oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_list = subset_train_list # 5 batches # or 20 batches\n",
        "train_list = full_train_list"
      ],
      "metadata": {
        "id": "uAuXH5YNiZCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1313131313)\n",
        "random_idx = np.random.randint(1,len(train_list),size=10)\n",
        "print(random_idx)\n",
        "fig = plt.figure(figsize=(20., 10.))\n",
        "\n",
        "for i, img_idx in enumerate(random_idx):\n",
        "    ax = fig.add_subplot(2,5,i+1)\n",
        "    img = Image.open(train_list[img_idx])\n",
        "    plt.imshow(img)\n",
        "    i+=1\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kPJdcRe0hfC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1313131313)\n",
        "random_idx = np.random.randint(1,len(train_list),size=10)\n",
        "print(random_idx)\n",
        "fig = plt.figure(figsize=(20., 10.))\n",
        "\n",
        "for i, img_idx in enumerate(random_idx):\n",
        "    ax = fig.add_subplot(2,5,i+1)\n",
        "    img = Image.open(train_list[img_idx])\n",
        "    print(type(img))\n",
        "    print(train_list[img_idx])\n",
        "    plt.imshow(img)\n",
        "    i+=1\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d5nzS5YCqCCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# %matplotlib inline  # if you are running this code in Jupyter notebook\n",
        "\n",
        "# reads image 'opencv-logo.png' as grayscale\n",
        "img = cv2.imread('local_data/train/dog.10678.jpg')[...,::-1] #same as [:,:,::-1]; opencv reads in bgr, but matplotlib uses rgb\n",
        "plt.imshow(img)\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "DCyVlQTbqkOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.resize(img[:,:170,:],[224,224]))"
      ],
      "metadata": {
        "id": "XnR-_QGrr--e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(cv2.resize(img[:,190:,:],[224,224]))"
      ],
      "metadata": {
        "id": "9ZMBA8tlsTb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1313131313)\n",
        "random_idx = np.random.randint(1,len(train_list),size=10)\n",
        "print(random_idx)\n",
        "fig = plt.figure(figsize=(20., 10.))\n",
        "\n",
        "for i, img_idx in enumerate(random_idx):\n",
        "    ax = fig.add_subplot(2,5,i+1)\n",
        "    img = cv2.imread(train_list[img_idx])[...,::-1] #same as [:,:,::-1]; opencv reads in bgr, but matplotlib uses rgb\n",
        "    h,w,c = img.shape\n",
        "    if h > w:\n",
        "      h = int(0.5 * h)\n",
        "      img = img[:,h:,:]\n",
        "    else:\n",
        "      w = int(0.5 * w)\n",
        "      img = img[w:,:,:]\n",
        "\n",
        "    img = cv2.resize(img,[224,224])\n",
        "    plt.imshow(img)\n",
        "    i+=1\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_q4VJ_NOw5wD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1313131313)\n",
        "random_idx = np.random.randint(1,len(train_list),size=10)\n",
        "print(random_idx)\n",
        "fig = plt.figure(figsize=(20., 10.))\n",
        "\n",
        "for i, img_idx in enumerate(random_idx):\n",
        "    ax = fig.add_subplot(2,5,i+1)\n",
        "    img = cv2.imread(train_list[img_idx])[...,::-1] #same as [:,:,::-1]; opencv reads in bgr, but matplotlib uses rgb\n",
        "    h,w,c = img.shape\n",
        "    img = img[:224,:224,:]\n",
        "\n",
        "\n",
        "    img = cv2.resize(img,[224,224])\n",
        "    plt.imshow(img)\n",
        "    i+=1\n",
        "\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4fJoTCeGyDXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self,file_list,transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "        \n",
        "    #dataset length\n",
        "    def __len__(self):\n",
        "        self.filelength = len(self.file_list)\n",
        "        return self.filelength\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = self.file_list[idx]\n",
        "        img = Image.open(img_path)\n",
        "        img_transformed = self.transform(img)\n",
        "        \n",
        "        label = img_path.split('/')[-1].split('.')[0]\n",
        "        if label == 'dog':\n",
        "            label=1\n",
        "        elif label == 'cat':\n",
        "            label=0\n",
        "            \n",
        "        return img_transformed,label,img_path"
      ],
      "metadata": {
        "id": "5mkkAwB9QpuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Visualization of Image Classification \n",
        "import torchvision\n",
        "def visualize_classification(loader_iter, nrofItems = 9, pad = 0) -> None:\n",
        "\n",
        "  #Iterate through the data loader\n",
        "  imgTensor, labels, _ = next(loader_iter)\n",
        "  labels = labels.tolist()\n",
        "\n",
        "  # Generate image grid\n",
        "  grid = torchvision.utils.make_grid(imgTensor[:nrofItems], padding = pad, nrow=nrofItems)\n",
        "\n",
        "  # Permute the axis as numpy expects image of shape (H x W x C) \n",
        "  grid = grid.permute(1, 2, 0)\n",
        "  \n",
        "  # Set up plot config\n",
        "  plt.figure(figsize=(8, 2), dpi=300)\n",
        "  plt.axis('off')\n",
        "\n",
        "  # Plot Image Grid\n",
        "  plt.imshow(grid)\n",
        "  \n",
        "  # # Plot the image titles\n",
        "  # fact = 1 + (nrofItems)/100\n",
        "  # rng = np.linspace(1/(fact*nrofItems), 1 - 1/(fact*nrofItems) , num = nrofItems)\n",
        "  # for idx, val in enumerate(rng):\n",
        "  #   plt.figtext(val, 0.85, labels[idx], fontsize=8)\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "c4nIL39aRC1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms =  transforms.Compose([ #these params work well for cats & dogs.:\n",
        "  # transforms.Resize((224, 224)),\n",
        "  transforms.RandomResizedCrop(224,scale=(0.2, 0.4)), \n",
        "  # transforms.RandomHorizontalFlip(),\n",
        "  # transforms.ColorJitter(brightness=.4, hue=.15),\n",
        "  transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "oM7KKpV1xSbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=10\n",
        "train_data = dataset(test_list, transform=train_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=False )\n"
      ],
      "metadata": {
        "id": "bV9pqApGQsU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this cell is here only because the Author apprently didn't understand how Dataset and Dataloaders behave - are they iterable, are they generators? - well they are hybrid. - , and wanted to see what happens\n",
        "# all but one cell can be commented\n",
        "# TODO: you don't need a separate loader. each iteration goes from the beginning\n",
        "# but its interesting that different augmentations get generated.\n",
        "iterator = iter(train_loader)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iterator)\n",
        "visualize_classification(iter(train_loader))\n",
        "visualize_classification(iter(train_loader))\n",
        "visualize_classification(iter(train_loader))"
      ],
      "metadata": {
        "id": "ZjY3EYQWQ-nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This was exploration code, now write a snipper that will actually save the imgs"
      ],
      "metadata": {
        "id": "rdXSf4P_TM5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rvf generated/"
      ],
      "metadata": {
        "id": "Vb8HK4TQc8Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "batch_size=1\n",
        "train_data = dataset(test_list, transform=train_transforms)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=False )\n",
        "\n",
        "\n",
        "epochs = 4\n",
        "# max = 1000\n",
        "os.makedirs('generated/', exist_ok=True)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\n\",\"=\"*30,\"\\n\")\n",
        "    epoch_loss = 0\n",
        "    epoch_accuracy = 0\n",
        "    \n",
        "    with tqdm(train_loader, unit=\"iteration\") as tepoch:      \n",
        "      for id, (data, label, filepath) in enumerate(tepoch):\n",
        "        out_path = filepath[0].split(\"/\")[-1].replace(\".jpg\",f\"_crop_e_{epoch}.jpg\")\n",
        "        str_label = \"cat\" if label.item() == 0 else \"dog\"\n",
        "        save_image(data,f\"generated/{out_path}\")\n",
        "        tepoch.set_description(f\"Generating transformed images, epoch {epoch}, iteration {id}\")\n",
        "        # if id >= max:\n",
        "          # break\n"
      ],
      "metadata": {
        "id": "VGOob8XmfI9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/cat_dogs_crops_from_test_20k | wc -l"
      ],
      "metadata": {
        "id": "7IX9VYylwj--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -rv generated/ /content/drive/MyDrive/cat_dogs_crops_from_test_20k"
      ],
      "metadata": {
        "id": "FMbnmFVMdXF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -rv 20k_from_test.zip /content/drive/MyDrive/20k_from_test.zip"
      ],
      "metadata": {
        "id": "W_DHkeED2Wbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r 20k_from_test.zip /content/drive/MyDrive/cat_dogs_crops_from_test_20k "
      ],
      "metadata": {
        "id": "CdmnRGcM2KKU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}